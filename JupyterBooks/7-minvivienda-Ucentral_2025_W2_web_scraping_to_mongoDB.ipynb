{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMku10CMKUFYW2IShBe67Sg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Maestría en \"Analítica de Datos\"\n","---\n","Nombre: Jader Antonio Gomez Orrego\n","\n","Código: 1018422976\n","\n","Fecha: 2025 Agosto 28\n","\n","---\n","Descripción: Web scraping en el Ministerio de Vivienda usando la librería requests\n","---"],"metadata":{"id":"EDjnjS8Ls-pQ"}},{"cell_type":"markdown","source":["#Taller para aprender a hacer WEB SCRAPING\n","\n","---\n","1. Instalar librerías (básicas).\n","2. Creación de los DOM (página web como la vería un humano en una pantalla).\n","3. Recorrido de objetos HTML (página web) y recorrido de los hipervínculos que estén en el dominio.\n","4. Descargar todos los PDF que estén linkeados/hipervinculados (acceso libre).\n","5. Extraer el texto de cada archivo PDF (normal/OCR) en español.\n","6. Generar archivos JSON por cada PDF.\n","7. Crear una base de datos en MongoAtlas.\n","8. Crear colección de archivos PDF.\n","9. Cargar los JSON a MongoAtlas.\n","\n"],"metadata":{"id":"nJNIgl4e4ATX"}},{"cell_type":"markdown","source":["# 0- Trabajar con google Drive"],"metadata":{"id":"-Wx5_Zyv4ymI"}},{"cell_type":"code","source":["# habilitamos drive de google desde colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpnVg_1i7-P3","executionInfo":{"status":"ok","timestamp":1760223470848,"user_tz":300,"elapsed":19077,"user":{"displayName":"Jader Gomez","userId":"00334149119996990000"}},"outputId":"3f7cc4aa-778e-4cad-9f67-0cb53549e6b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# 1- Instalar librerías (básicas)."],"metadata":{"id":"4B7Bs0Q98SW6"}},{"cell_type":"code","source":["!pip install requests\n","!pip install beautifulsoup4\n","!pip install pymongo\n","!pip install lxml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPx3La7M8Q5b","executionInfo":{"status":"ok","timestamp":1760223502945,"user_tz":300,"elapsed":27422,"user":{"displayName":"Jader Gomez","userId":"00334149119996990000"}},"outputId":"1f705af1-473a-4864-96b5-02ed428c8b02","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n","Collecting pymongo\n","  Downloading pymongo-4.15.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n","  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n","Downloading pymongo-4.15.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dnspython, pymongo\n","Successfully installed dnspython-2.8.0 pymongo-4.15.3\n","Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (5.4.0)\n"]}]},{"cell_type":"markdown","source":["# 2- Creación de los DOM inicial,\n","*Buscar el DIV class=\"sectiona_Accordion\"\n","*Vamos a buscar los hipervinculos y los liste"],"metadata":{"id":"P3C33-faAWp1"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","url      = 'https://minvivienda.gov.co/normativa?f%5B0%5D=tematica%3A1772'\n","response = requests.get(url)\n","soup     = BeautifulSoup(response.content, 'lxml')\n","\n","# encontrar nuestro div maestro una clase =\"section-accordion\"\n","container_div = soup.find('div',class_='az-ctnr container') #id=internasContainer\n","\n","# vamos a buscar todos los hipervinculos y los liste\n","if container_div:\n","  hipervinculos = container_div.find_all('a')\n","  for hipervinculo in hipervinculos:\n","    print(hipervinculo.get('href'))\n","else:\n","  print(\"No se encontró el div con la clase especificada.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejxIw30NB5aN","executionInfo":{"status":"ok","timestamp":1760224798259,"user_tz":300,"elapsed":297,"user":{"displayName":"Jader Gomez","userId":"00334149119996990000"}},"outputId":"8dde93b9-6079-420c-9cf6-cffd333fbb0b","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/normativa?f%5B0%5D=tipo_normativa%3ALey#views-exposed-form-normativa-block-1\n","/normativa?f%5B0%5D=tipo_normativa%3ADecreto#views-exposed-form-normativa-block-1\n","/normativa?f%5B0%5D=tipo_normativa%3AResoluci%C3%B3n#views-exposed-form-normativa-block-1\n","/normativa?f%5B0%5D=tipo_normativa%3ACircular#views-exposed-form-normativa-block-1\n","/normativa?f%5B0%5D=tipo_normativa%3ACONPES#views-exposed-form-normativa-block-1\n","/normativa?f%5B0%5D=tipo_normativa%3AAuto#views-exposed-form-normativa-block-1\n","/normativa?f%5B0%5D=tipo_normativa%3AAcuerdo#views-exposed-form-normativa-block-1\n","/normativa/decreto-1077-2015\n","/ministerio/conceptos-juridicos\n","/normativa/agenda-regulatoria\n"]}]},{"cell_type":"markdown","source":["# 3- crear un JSON que recorra donde se guarde los hipervinculos de cada uno de los DOOM's de las páginas hijas"],"metadata":{"id":"JEhyvAsRUvq1"}},{"cell_type":"markdown","source":["## 3.1 librerias requeridas"],"metadata":{"id":"fz4JStmfVd8N"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import json\n","from urllib.parse import urljoin\n","import os"],"metadata":{"id":"rpu7xCNzVkAx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.2 función especializada"],"metadata":{"id":"bRDpM8q5V27a"}},{"cell_type":"code","source":["def extraer_hipervinculos(url):\n","  \"\"\"ingfrese a la url cree el DOOM y extraiga los hipervinculos pewro solamente los ASPX y PDF\"\"\"\n","  try:\n","    response = requests.get(url)\n","    response.raise_for_status()\n","    soup = BeautifulSoup(response.content, 'lxml')\n","    container_div = soup.find('div', class_='az-ctnr container')\n","    all_links = [] # Use a different name for the list\n","    if container_div:\n","      for link in container_div.find_all('a'): #recorrer los hipervinculos de la pagina (hija/nieta/bisnieta)\n","        href = link.get('href')\n","        if href:\n","          full_url = urljoin(url, href)\n","          # Corrected syntax for startswith and endswith conditions\n","          if full_url.startswith('https://minvivienda.gov.co/normativa?f%5B0%5D=tematica%3A1772/'):\n","            if full_url.endswith('.aspx'):\n","              all_links.append({'url': full_url,'type':'aspx'})\n","            elif full_url.endswith('.pdf'): # Use elif for the second condition\n","              all_links.append({'url': full_url,'type':'pdf'})\n","\n","    return all_links # Return the list of links\n","\n","  except requests.exceptions.RequestException as e:\n","    print(f\"Error al acceder a la página: {url}: {e}\")"],"metadata":{"id":"6tL9WR_HV837"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.3 crear el JSON  con el web scraping"],"metadata":{"id":"ik7GLSolMQlB"}},{"cell_type":"code","source":["# json_file_path = '/content/drive/MyDrive/BigData/web_scraping/links_mintic.json'\n","# if (os.path.exists(json_file_path)):\n","#   os.remove(json_file_path)\n","# todos_los_links=[]\n","# aspx_links_a_visitar = extraer_hipervinculos('https://www.minsalud.gov.co/Normativa/')\n","\n","# print (aspx_links_a_visitar)\n","# while aspx_links_a_visitar:\n","#   for link in aspx_links_a_visitar:\n","#     print(link)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CkKeG01jAEP","executionInfo":{"status":"ok","timestamp":1760111900019,"user_tz":300,"elapsed":1228,"user":{"displayName":"Jader Gomez","userId":"00334149119996990000"}},"outputId":"ca9097a6-b9c8-42f7-9f4a-ef9258632497"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cd6df548","executionInfo":{"status":"ok","timestamp":1760225398964,"user_tz":300,"elapsed":8954,"user":{"displayName":"Jader Gomez","userId":"00334149119996990000"}},"outputId":"b86d88c6-cbe6-4fab-8a87-c2ae28d2926f"},"source":["!pip install selenium"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.36.0-py3-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n","Collecting trio<1.0,>=0.30.0 (from selenium)\n","  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n","  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.10.5)\n","Requirement already satisfied: typing_extensions<5.0,>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n","Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (25.4.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (3.10)\n","Collecting outcome (from trio<1.0,>=0.30.0->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (1.3.1)\n","Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n","Downloading selenium-4.36.0-py3-none-any.whl (9.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio-0.31.0-py3-none-any.whl (512 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n","Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n","Successfully installed outcome-1.3.0.post0 selenium-4.36.0 trio-0.31.0 trio-websocket-0.12.2 wsproto-1.2.0\n"]}]},{"cell_type":"code","source":["import os, json, time\n","import requests\n","from bs4 import BeautifulSoup\n","from urllib.parse import urljoin\n","\n","# --- CONFIG ---\n","HEADERS = {\n","    \"User-Agent\": (\n","        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n","        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n","        \"Chrome/120.0.0.0 Safari/537.36\"\n","    )\n","}\n","\n","def extraer_hipervinculos(url):\n","    \"\"\"\n","    Devuelve una lista de dicts con forma:\n","    {\"url\": url_absoluta, \"type\": \"aspx\"|\"pdf\"|\"html\"|\"otro\"}\n","    \"\"\"\n","    r = requests.get(url, headers=HEADERS, timeout=30)\n","    r.raise_for_status()\n","    soup = BeautifulSoup(r.content, \"lxml\")\n","\n","    links = []\n","    for a in soup.find_all(\"a\", href=True):\n","        href = a[\"href\"].strip()\n","        abs_url = urljoin(url, href)\n","\n","        l = abs_url.lower()\n","        if l.endswith(\".pdf\"):\n","            tipo = \"pdf\"\n","        elif \".aspx\" in l:\n","            tipo = \"aspx\"\n","        elif l.startswith(\"http\"):\n","            tipo = \"html\"\n","        else:\n","            tipo = \"otro\"\n","\n","        links.append({\"url\": abs_url, \"type\": tipo})\n","\n","    return links\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWlI9hWAMc4a","executionInfo":{"status":"ok","timestamp":1760225889457,"user_tz":300,"elapsed":323,"user":{"displayName":"Jader Gomez","userId":"00334149119996990000"}},"outputId":"4a3dfacc-9338-47aa-e06c-055a2b5059f8","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Seed (páginas para visitar): 0\n","Se creó el archivo JSON /content/drive/MyDrive/BigData/web_scraping/links_minagricultura.json con 0 enlaces\n","Páginas .aspx visitadas: 0\n"]}]},{"cell_type":"markdown","source":["# 4- Recorrer JSON con los hiperviculos y descargar todos los PDF's"],"metadata":{"id":"XgqRJn-GKukH"}},{"cell_type":"code","source":["pdf_dir='/content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs' # Changed from file path to directory path\n","os.makedirs(pdf_dir, exist_ok=True) #creamos la carpeta  si no existe\n","json_file_path = '/content/drive/MyDrive/BigData/web_scraping/links_minagricultura.json'\n","with open(json_file_path, 'r') as json_file:\n","  data = json.load(json_file)\n","  links = data['links']\n","  for link in links:\n","    if link['type'] == 'pdf':\n","      try:\n","        response = requests.get(link['url'], stream=True)\n","        response.raise_for_status()\n","        file_name = os.path.join(pdf_dir, os.path.basename(link['url']))\n","        with open(file_name, 'wb') as pdf_file:\n","          for chunk in response.iter_content(chunk_size=8192):\n","            pdf_file.write(chunk)\n","        print(f\"Archivo PDF descargado: {file_name}\")\n","      except requests.exceptions.RequestException as e:\n","        print(f\"Error al descargar el archivo PDF: {link['url']}: {e}\")"],"metadata":{"id":"i5X4leAjXXFc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5- Extraer los textos de los pdf's y generar JSON por cada PDF"],"metadata":{"id":"tYUiN9XiQbJy"}},{"cell_type":"markdown","source":["## 5.1 Instalar librerias especializadas para trabajar con PDF (OCR)"],"metadata":{"id":"-84t-3vAQpiG"}},{"cell_type":"code","source":["!apt-get update\n","!apt-get install tesseract-ocr\n","!apt-get install libtesseract-dev\n","!apt-get install tesseract-ocr-spa\n","\n","# Instalar librerias para trabajar con imagenes\n","!pip install pytesseract pillow\n","\n","!pip install matplotlib-venn\n","\n","!pip install pdfminer.six pdf2image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"m5PnKWI4Q5Ic","executionInfo":{"status":"ok","timestamp":1760221794084,"user_tz":300,"elapsed":45321,"user":{"displayName":"Jader Gomez","userId":"00334149119996990000"}},"outputId":"1bbdef2d-0be7-4f2b-88b3-9bed751959a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","\r0% [Waiting for headers] [1 InRelease 0 B/129 kB 0%] [Connected to cloud.r-proj\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\r0% [1 InRelease 48.9 kB/129 kB 38%] [Connected to cloud.r-project.org (108.157.\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","\r                                                                               \rHit:4 https://cli.github.com/packages stable InRelease\n","Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n","Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,276 kB]\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,425 kB]\n","Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,077 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,751 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,584 kB]\n","Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,813 kB]\n","Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,354 kB]\n","Get:19 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.8 kB]\n","Fetched 24.7 MB in 3s (8,665 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","tesseract-ocr is already the newest version (4.1.1-2.1build1).\n","0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libarchive-dev libleptonica-dev\n","The following NEW packages will be installed:\n","  libarchive-dev libleptonica-dev libtesseract-dev\n","0 upgraded, 3 newly installed, 0 to remove and 46 not upgraded.\n","Need to get 3,743 kB of archives.\n","After this operation, 16.0 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.5 [581 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n","Fetched 3,743 kB in 0s (13.4 MB/s)\n","Selecting previously unselected package libarchive-dev:amd64.\n","(Reading database ... 126675 files and directories currently installed.)\n","Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.5_amd64.deb ...\n","Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n","Selecting previously unselected package libleptonica-dev.\n","Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n","Unpacking libleptonica-dev (1.82.0-3build1) ...\n","Selecting previously unselected package libtesseract-dev:amd64.\n","Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n","Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n","Setting up libleptonica-dev (1.82.0-3build1) ...\n","Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n","Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  tesseract-ocr-spa\n","0 upgraded, 1 newly installed, 0 to remove and 46 not upgraded.\n","Need to get 951 kB of archives.\n","After this operation, 2,309 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-spa all 1:4.00~git30-7274cfa-1.1 [951 kB]\n","Fetched 951 kB in 0s (4,524 kB/s)\n","Selecting previously unselected package tesseract-ocr-spa.\n","(Reading database ... 126808 files and directories currently installed.)\n","Preparing to unpack .../tesseract-ocr-spa_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n","Unpacking tesseract-ocr-spa (1:4.00~git30-7274cfa-1.1) ...\n","Setting up tesseract-ocr-spa (1:4.00~git30-7274cfa-1.1) ...\n","Collecting pytesseract\n","  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n","Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n","Installing collected packages: pytesseract\n","Successfully installed pytesseract-0.3.13\n","Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.12/dist-packages (1.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from matplotlib-venn) (1.16.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->matplotlib-venn) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.17.0)\n","Collecting pdfminer.six\n","  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n","Collecting pdf2image\n","  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six) (3.4.3)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six) (43.0.3)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pdf2image) (11.3.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six) (2.0.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.23)\n","Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n","Installing collected packages: pdf2image, pdfminer.six\n","Successfully installed pdf2image-1.17.0 pdfminer.six-20250506\n"]}]},{"cell_type":"markdown","source":["## 5.1 Instanciar librerias especializadas para trabajar con PDF (OCR)"],"metadata":{"id":"Ln8Ti9sSXtWz"}},{"cell_type":"code","source":["from io import StringIO\n","from datetime import datetime\n","import pytesseract\n","from PIL import Image\n","#librerias para trabajar con PDF\n","from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n","from pdfminer.converter import TextConverter\n","from pdfminer.layout import LAParams\n","from pdfminer.pdfpage import PDFPage"],"metadata":{"id":"9yw0VLKaX7kU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extraer_texto_desde_pdf(pdf_path):\n","  try:\n","    rsrcmgr = PDFResourceManager()\n","    retstr = StringIO()\n","    laparams = LAParams()\n","    device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n","    fp = open(pdf_path, 'rb')\n","    interpreter = PDFPageInterpreter(rsrcmgr, device)\n","    text = \"\" # Initialize text here\n","    for page in PDFPage.get_pages(fp, caching=True, check_extractable=True):\n","      interpreter.process_page(page)\n","    text = retstr.getvalue() # Get the text after processing all pages\n","    fp.close()\n","    device.close()\n","    retstr.close()\n","    if text.strip():\n","      return text, 'normal', True\n","\n","  except Exception as e:\n","    print(f\"Error al extraer texto desde el PDF (normal): {pdf_path}: {e}\")\n","\n","  #SINO pudo por el metodo normal intente con OCR\n","  try:\n","    from pdf2image import convert_from_path\n","    images = convert_from_path(pdf_path)\n","    ocr_text = '' # Initialize ocr_text here\n","    for i, image in enumerate(images):\n","      ocr_text += pytesseract.image_to_string(image, lang='spa')\n","    if ocr_text.strip():\n","      return ocr_text, 'OCR', True\n","    else:\n","      print(f\"OCR de texto no fue posible: {pdf_path}\")\n","      return \"\",'OCR', False\n","\n","  except Exception as e:\n","    print(f\"Error en extracción del texto con OCR: {pdf_path}: {e}\")"],"metadata":{"id":"B82mAU7XY-z_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pdf_dir='/content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs'\n","json_output_dir = '/content/drive/MyDrive/BigData/web_scraping/minagricultura_json'\n","error_json_path='/content/drive/MyDrive/BigData/web_scraping/error_json.json'\n","\n","os.makedirs(json_output_dir, exist_ok=True) #creamos la carpeta si no existe\n","\n","pdf_archivos = [f for f in os.listdir(pdf_dir) if f.endswith('.pdf')]\n","error_archivos=[]\n","#reprocesar cada archivo pdf\n","for i, pdf_archivo in enumerate(pdf_archivos):\n","  try:\n","    print(f\"Procesando archivo PDF {i + 1}/{len(pdf_archivos)}: {pdf_archivo}\")\n","    pdf_path = os.path.join(pdf_dir, pdf_archivo)\n","    texto, metodo, succes = extraer_texto_desde_pdf(pdf_path)\n","    if succes:\n","      json_data={\n","          \"archivo\": pdf_archivo,\n","          \"fecha\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n","          \"texto\": texto,\n","          \"metodo\": metodo\n","      }\n","      #guardar un archivo JSON con una secuencia\n","      json_file = f\"minagricultura_{i+1}.json\"\n","      json_file_path = os.path.join(json_output_dir, json_file)\n","      with open(json_file_path, 'w', encoding='utf-8') as json_file:\n","        json.dump(json_data, json_file, indent=4, ensure_ascii=False)\n","      print(f\"PDF: {pdf_archivo} => JSON creado: {json_file_path}\")\n","    else:\n","      error_archivos.append(pdf_archivo)\n","      print(f\"Error al procesar el archivo PDF: {pdf_archivo}\")\n","  except Exception as e:\n","    error_archivos.append(pdf_archivo)\n","    print(f\"Error al procesar el archivo PDF: {pdf_archivo}: {e}\")\n","\n","if len(error_archivos) > 0:\n","  error_json = {\"error_archivos\": error_archivos}\n","  with open(error_json_path, 'w') as json_file:\n","    json.dump(error_json, json_file, indent=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Ap5PX2-QgvAo","executionInfo":{"status":"ok","timestamp":1760221899659,"user_tz":300,"elapsed":42811,"user":{"displayName":"Jader Gomez","userId":"00334149119996990000"}},"outputId":"a1376fee-031a-4911-809a-bd29a277610e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Procesando archivo PDF 1/20: MARIA GLORIA BUITRAGO.pdf\n","Error en extracción del texto con OCR: /content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs/MARIA GLORIA BUITRAGO.pdf: Unable to get page count. Is poppler installed and in PATH?\n","Error al procesar el archivo PDF: MARIA GLORIA BUITRAGO.pdf: cannot unpack non-iterable NoneType object\n","Procesando archivo PDF 2/20: MARIA GLORIA BUITRAGO GRANADA.pdf\n","Error en extracción del texto con OCR: /content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs/MARIA GLORIA BUITRAGO GRANADA.pdf: Unable to get page count. Is poppler installed and in PATH?\n","Error al procesar el archivo PDF: MARIA GLORIA BUITRAGO GRANADA.pdf: cannot unpack non-iterable NoneType object\n","Procesando archivo PDF 3/20: municipio de cerete 26-08-2016.pdf\n","Error en extracción del texto con OCR: /content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs/municipio de cerete 26-08-2016.pdf: Unable to get page count. Is poppler installed and in PATH?\n","Error al procesar el archivo PDF: municipio de cerete 26-08-2016.pdf: cannot unpack non-iterable NoneType object\n","Procesando archivo PDF 4/20: monica liliana monroy 16-08-2016.pdf\n","Error en extracción del texto con OCR: /content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs/monica liliana monroy 16-08-2016.pdf: Unable to get page count. Is poppler installed and in PATH?\n","Error al procesar el archivo PDF: monica liliana monroy 16-08-2016.pdf: cannot unpack non-iterable NoneType object\n","Procesando archivo PDF 5/20: martha isabel leguizamo peña 18-04-2016.pdf\n","Error en extracción del texto con OCR: /content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs/martha isabel leguizamo peña 18-04-2016.pdf: Unable to get page count. Is poppler installed and in PATH?\n","Error al procesar el archivo PDF: martha isabel leguizamo peña 18-04-2016.pdf: cannot unpack non-iterable NoneType object\n","Procesando archivo PDF 6/20: maria cristina manrique 24-05-2016.pdf\n","Error en extracción del texto con OCR: /content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs/maria cristina manrique 24-05-2016.pdf: Unable to get page count. Is poppler installed and in PATH?\n","Error al procesar el archivo PDF: maria cristina manrique 24-05-2016.pdf: cannot unpack non-iterable NoneType object\n","Procesando archivo PDF 7/20: luis guillermo rubiano 02-06-2016.pdf\n","Error en extracción del texto con OCR: /content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs/luis guillermo rubiano 02-06-2016.pdf: Unable to get page count. Is poppler installed and in PATH?\n","Error al procesar el archivo PDF: luis guillermo rubiano 02-06-2016.pdf: cannot unpack non-iterable NoneType object\n","Procesando archivo PDF 8/20: libia juliana pineda 02-06-2016.pdf\n","Error en extracción del texto con OCR: /content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs/libia juliana pineda 02-06-2016.pdf: Unable to get page count. Is poppler installed and in PATH?\n","Error al procesar el archivo PDF: libia juliana pineda 02-06-2016.pdf: cannot unpack non-iterable NoneType object\n","Procesando archivo PDF 9/20: humberto portilla montenegro 18-01-2016.pdf\n","Error en extracción del texto con OCR: /content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs/humberto portilla montenegro 18-01-2016.pdf: Unable to get page count. Is poppler installed and in PATH?\n","Error al procesar el archivo PDF: humberto portilla montenegro 18-01-2016.pdf: cannot unpack non-iterable NoneType object\n","Procesando archivo PDF 10/20: hernan jose barreto 24-05-2016.pdf\n","Error en extracción del texto con OCR: /content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs/hernan jose barreto 24-05-2016.pdf: Unable to get page count. Is poppler installed and in PATH?\n","Error al procesar el archivo PDF: hernan jose barreto 24-05-2016.pdf: cannot unpack non-iterable NoneType object\n","Procesando archivo PDF 11/20: Sentencia Corte Constitucional C-420-20.pdf\n","PDF: Sentencia Corte Constitucional C-420-20.pdf => JSON creado: /content/drive/MyDrive/BigData/web_scraping/minagricultura_json/minsalud_11.json\n","Procesando archivo PDF 12/20: Sentencia Corte Suprema de Justicia 76171 -2020.pdf\n","Error en extracción del texto con OCR: /content/drive/MyDrive/BigData/web_scraping/minagricultura_pdfs/Sentencia Corte Suprema de Justicia 76171 -2020.pdf: Unable to get page count. Is poppler installed and in PATH?\n","Error al procesar el archivo PDF: Sentencia Corte Suprema de Justicia 76171 -2020.pdf: cannot unpack non-iterable NoneType object\n","Procesando archivo PDF 13/20: Sentencia Corte Constitucional C-410-20.pdf\n","PDF: Sentencia Corte Constitucional C-410-20.pdf => JSON creado: /content/drive/MyDrive/BigData/web_scraping/minagricultura_json/minsalud_13.json\n","Procesando archivo PDF 14/20: AGENDA REGULATORIA SECTOR AGRICULTURA Y DESARROLLO RURAL 2025.pdf\n","PDF: AGENDA REGULATORIA SECTOR AGRICULTURA Y DESARROLLO RURAL 2025.pdf => JSON creado: /content/drive/MyDrive/BigData/web_scraping/minagricultura_json/minsalud_14.json\n","Procesando archivo PDF 15/20: AGENDA REGULATORIA 2024-ACTUALIZADA.pdf\n","PDF: AGENDA REGULATORIA 2024-ACTUALIZADA.pdf => JSON creado: /content/drive/MyDrive/BigData/web_scraping/minagricultura_json/minsalud_15.json\n","Procesando archivo PDF 16/20: AGENDA REGULATORIA SECTOR AGRICULTURA Y DESARROLLO RURAL 2024 30-01-2024.pdf\n","PDF: AGENDA REGULATORIA SECTOR AGRICULTURA Y DESARROLLO RURAL 2024 30-01-2024.pdf => JSON creado: /content/drive/MyDrive/BigData/web_scraping/minagricultura_json/minsalud_16.json\n","Procesando archivo PDF 17/20: Agenda Regulatoria 05-07-2023 (4).pdf\n","PDF: Agenda Regulatoria 05-07-2023 (4).pdf => JSON creado: /content/drive/MyDrive/BigData/web_scraping/minagricultura_json/minsalud_17.json\n","Procesando archivo PDF 18/20: Agenda Regulatoria 2023-02-03.pdf\n","PDF: Agenda Regulatoria 2023-02-03.pdf => JSON creado: /content/drive/MyDrive/BigData/web_scraping/minagricultura_json/minsalud_18.json\n","Procesando archivo PDF 19/20: Agenda Regulatoria 2023-17-01.pdf\n","PDF: Agenda Regulatoria 2023-17-01.pdf => JSON creado: /content/drive/MyDrive/BigData/web_scraping/minagricultura_json/minsalud_19.json\n","Procesando archivo PDF 20/20: Agenda Regulatoria 2023.pdf\n","PDF: Agenda Regulatoria 2023.pdf => JSON creado: /content/drive/MyDrive/BigData/web_scraping/minagricultura_json/minsalud_20.json\n"]}]},{"cell_type":"markdown","source":["# 6- Cragar los JSON a mongo Atlas"],"metadata":{"id":"Qm35mK8EomrW"}},{"cell_type":"code","source":["from pymongo import MongoClient\n","\n","#reemplazar el <db_password>\n","uri =\"mongodb+srv://DBJAGO:Col2024-@cluster0.ckuwkho.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n","client = MongoClient(uri)\n","client.stats"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umiN835VovVs","executionInfo":{"status":"ok","timestamp":1760222083113,"user_tz":300,"elapsed":1026,"user":{"displayName":"Jader Gomez","userId":"00334149119996990000"}},"outputId":"ef15e3ed-4e4f-4530-fd3c-18a8a0179b2a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Database(MongoClient(host=['ac-c3zkvgv-shard-00-01.ckuwkho.mongodb.net:27017', 'ac-c3zkvgv-shard-00-02.ckuwkho.mongodb.net:27017', 'ac-c3zkvgv-shard-00-00.ckuwkho.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, retrywrites=True, w='majority', appname='Cluster0', authsource='admin', replicaset='atlas-13bf44-shard-0', tls=True), 'stats')"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["db_name='minagricultura'\n","db = client[db_name]\n","#creamos la colección\n","collection_name='normatividad'\n","collection = db[collection_name]\n","print(\"base de datos y colección creadas\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwzTLBhkpNpI","executionInfo":{"status":"ok","timestamp":1760222084441,"user_tz":300,"elapsed":50,"user":{"displayName":"Jader Gomez","userId":"00334149119996990000"}},"outputId":"922ce067-29d1-489c-b862-34455720e1fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["base de datos y colección creadas\n"]}]},{"cell_type":"code","source":["json_output_dir = '/content/drive/MyDrive/BigData/web_scraping/minagricultura_json'\n","json_archivos = [f for f in os.listdir(json_output_dir) if f.endswith('.json')]\n","\n","contar_cargados=0\n","json_no_cargados=[]\n","print(f\"cargando {len(json_archivos)} JSON a mongo\")\n","for json_archivo in json_archivos:\n","  json_path = os.path.join(json_output_dir, json_archivo)\n","  with open(json_path, 'r') as json_file:\n","    json_data = json.load(json_file)\n","  insert_result = collection.insert_one(json_data)\n","  if insert_result.inserted_id:\n","    print(f\"json {json_archivo} cargado con exito\")\n","    contar_cargados+=1\n","  else:\n","    print(f\"Error al cargar el archivo JSON: {json_archivo}\")\n","    json_no_cargados.append(json_archivo)\n","print(f\"se cargaron {contar_cargados} JSON a mongo\")\n","print(\"no se pudieron cargar:\",json_no_cargados)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9IPczXTpovw","executionInfo":{"status":"ok","timestamp":1760222087988,"user_tz":300,"elapsed":562,"user":{"displayName":"Jader Gomez","userId":"00334149119996990000"}},"outputId":"d98d1c43-acfe-493d-bdf8-21150879d827"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cargando 9 JSON a mongo\n","json minsalud_11.json cargado con exito\n","json minsalud_13.json cargado con exito\n","json minsalud_14.json cargado con exito\n","json minsalud_15.json cargado con exito\n","json minsalud_16.json cargado con exito\n","json minsalud_17.json cargado con exito\n","json minsalud_18.json cargado con exito\n","json minsalud_19.json cargado con exito\n","json minsalud_20.json cargado con exito\n","se cargaron 9 JSON a mongo\n","no se pudieron cargar: []\n"]}]},{"cell_type":"markdown","source":["##"],"metadata":{"id":"jlRf0_qfXhEv"}}]}